---
title: "prem_analysis"
author: "Catharina Vendl, Patrice Pottier, Matthew Taylor, Jennifer Braeunig, Matthew Gibson, Daniel Hesselson, G. Gregory Neely, Malgorzata Lagisz, Shinichi Nakagawa "
date: "latest update: `r format(Sys.time(), '%d %B %Y')`"
output: rmdformats::material

---
# **Packages and custom functions**

```{r setup, include = FALSE}
# knitr setting
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE, 
  tidy = TRUE,
  cache = TRUE, 
  echo=TRUE
)

# this needs to be installed from github
#remotes::install_github("rvlenth/emmeans", dependencies = TRUE, build_opts = "")  # Note that the installation may not work if the folder is synchronising with OneDrive
```


The `lnRR_func` function is here used to calculate a log response ratio (lnRR) adjusted for small sample sizes. In addition, this formula accounts for correlated samples. 
For more details, see *Doncaster and Spake (2018) Correction for bias in meta-analysis of little-replicated studies. Methods in Ecology and Evolution; 9:634-644*

```{r}
# packages
library(tidyverse)
library(here)
library(metafor)
library(metaAidR)
library(orchaRd)
library(ape)
library(clubSandwich)
library(metaAidR)
library(patchwork)
library(emmeans)
library(kableExtra)

# custom functions - here
# this is to get small sample size corrected lnRR
# also, the correlated samples - MS should put formulas of what we used and assumptions
# averaged 
lnRR_func <- function(Mc, Nc, Me, Ne, aCV2c, aCV2e, rho = 0.8){
  lnRR <- log(Me/Mc) + 
        0.5 * ((aCV2e/Ne) - (aCV2c/Nc))	
  
  var_lnRR <- (aCV2c/Nc) + (aCV2e/Ne) + 
         rho*(sqrt(aCV2c)*sqrt(aCV2e)/(Nc+Ne))
  
  data.frame(lnRR,var_lnRR)
}

# Mc: Concentration of PFAS of the raw (control) sample
# Nc: Sample size of the raw (control) sample
# Me: Concentration of PFAS of the cooked (experimental) sample
# Ne: Sample size of the cooked (experimental) sample 
# aCV2c: Mean coefficient of variation of the raw (control) samples
# aCV2e: Mean coefficient of variation of the cooked (experimental) samples


```

# **Data import and processing**

## Import data 

**DETAILS ABOUT DATA PRE-PROCESSING NEED TO BE ADDED**

```{r data}

pre_processed_data <- read_csv(here("data", "pilot_data_preprocessed.csv")) 

pre_processed_data

# creating SD for just biological
# not quite sure why if_else does not work but ifesle does (handling NA???)

dat <- pre_processed_data %>% mutate(SDc = ifelse(Sc_technical_biological == "biological", Sc, NA), # Calculate the SD of biological replicates for control samples
                                     SDe = ifelse(Se_technical_biological == "biological", Se, NA)) # Calculate the SD of biological replicates for experimental samples

```
## Import phylogenetic information and calculate phylogenetic variance-covariance matrix 

The phylogenetic tree was generated in the `tree_cooked_fish_MA.Rmd` document 

```{r, fig.height=10, fig.width = 8}

tree <- read.tree(here("data", "plot_cooked_fish_MA.tre")) # Import phylogenetic tree (see tree_cooked_fish_MA.Rmd for more details) 

tree <- compute.brlen(tree) # Generate branch lengths 

cor_tree <- vcv(tree,corr = T) # Generate phylogenetic variance-covariance matrix 

dat$Phylogeny <- str_replace(dat$Species_Scientific, " ", "_") # Add the `phylogeny` column to the data frame

colnames(cor_tree) %in% dat$Phylogeny # Check correspondence between tip names and data frame

plot(tree)
```



## Calculate effect sizes 

The average coefficient of variation in PFAS concentration was calculated for each study and treatment, according to *Doncaster and Spake (2018) Correction for bias in meta-analysis of little-replicated studies. Methods in Ecology and Evolution; 9:634-644*. 
Then, these values were averaged across studies and used to calculate the lnRR corrected for small sample sizes (for formula, see the `lnRR_func` above)

```{r}
aCV2 <- dat %>% 
               group_by(Study_ID) %>%  # Group by study 
                                     summarise(CV2c = mean((SDc/Mc)^2, na.rm = T),  # Calculate the squared coefficient of variation for control and experimental groups
                                               CV2e = mean((SDe/Me)^2, na.rm = T)) %>% 
                                                                                      ungroup() %>% # ungroup 
                                                                                                   summarise(aCV2c = mean(CV2c, na.rm = T), # Mean CV^2 for exp and control groups across studies
                                                                                                             aCV2e = mean(CV2e, na.rm = T)) 

effect <- lnRR_func(Mc = dat$Mc, 
                    Nc = dat$Nc, 
                    Me = dat$Me, 
                    Ne = dat$Ne, 
                    aCV2c = aCV2[[1]], 
                    aCV2e = aCV2[[2]],
                    rho = 0.8)  # Calculate effect sizes

dat <- dat %>% 
             mutate(N_tilde = (Nc*Ne)/(Nc + Ne)) # Calculate the effective sample size

dat <- cbind(dat, effect) # Merge effect sizes with the data frame

VCV_lnRR <- make_VCV_matrix(dat, V = "var_lnRR", cluster = "Cohort_ID", obs = "Effect_ID", rho = 0.5) # Because some effect sizes share the same control, we generated a variance-covariance matrix to account for correlated errors (i.e. effectively dividing the weight of the correlated estimates by half)

```

## Distribution of effect sizes 

```{r, fig.height=8, fig.width=8}
# mean 
ggplot(dat, aes(x=lnRR))+ geom_histogram(fill = "salmon", col = "black", binwidth = 0.2) + theme_classic()

# variance
ggplot(dat, aes(x=var_lnRR))+ geom_histogram(fill = "salmon", col = "black", binwidth = 0.05) + theme_classic()

# log variance
ggplot(dat, aes(x=var_lnRR))+ geom_histogram(fill = "salmon", col = "black", binwidth = 0.05) + scale_x_log10()+theme_classic()
```

# **Sample sizes**

## Table of sample sizes 

```{r}
dat %>%
       summarise( # Calculate the number of effect sizes, studies and species for the main categorical variables
                 `Studies` = n_distinct(Study_ID),
                 `Species` = n_distinct(Species_common),
                 `PFAS type` = n_distinct(PFAS_type),
                 `Cohorts` = n_distinct(Cohort_ID),
                 `Effect sizes` = n_distinct(Effect_ID),
    
                 `Effect sizes (Oil-based)` = n_distinct(Effect_ID[Cooking_Category=="oil-based"]),
                 `Studies (Oil-based)` = n_distinct(Study_ID[Cooking_Category=="oil-based"]),
                 `Species (Oil-based)` = n_distinct(Species_common[Cooking_Category=="oil-based"]),

                 `Effect sizes (Water-based)` = n_distinct(Effect_ID[Cooking_Category=="water-based"]),
                 `Studies (Water-based)` = n_distinct(Study_ID[Cooking_Category=="water-based"]),
                 `Species (Water-based)` = n_distinct(Species_common[Cooking_Category=="water-based"]),

                 `Effect sizes (No liquid)` = n_distinct(Effect_ID[Cooking_Category=="No liquid"]),
                 `Studies (No liquid)` = n_distinct(Study_ID[Cooking_Category=="No liquid"]),
                 `Species (No liquid)` = n_distinct(Species_common[Cooking_Category=="No liquid"]),) -> table_sample_sizes

table_sample_sizes<-t(table_sample_sizes)
colnames(table_sample_sizes)<-"n (sample size)"
kable(table_sample_sizes) %>% kable_styling("striped", position="left")
```

## Summary of the dataset 

```{r}
summary(dat)
```


# **Intercept meta-analytical model**

## Determine the random effect structure

`Cohort_ID` explains virtually no variance in the model. Hence, it was removed from the model. All the other random effects explained significant variance and were kept in subsequent models 

```{r}

MA_all_rand_effects <- rma.mv(lnRR, VCV_lnRR, # Add `VCV_lnRR` to account for correlated errors errors between cohorts (shared_controls)
              random = list(~1|Study_ID, # Identity of the study
                            ~1|Phylogeny, # Phylogenetic correlation
                            ~1|Cohort_ID, # Identity of the cohort (shared controls)
                            ~1|Species_common, # Non-phylogenetic correlation between species
                            ~1|PFAS_type, # Type of PFAS 
                            ~1|Effect_ID), # Effect size identity 
              R= list(Phylogeny = cor_tree), # Assign the 'Phylogeny' argument to the phylogenetic variance-covariance matrix
              test = "t", 
              data = dat)

summary(MA_all_rand_effects) # Cohort ID does not explain any variance 

```


## Intercept meta-analytical model and percentage of heterogeneity 

```{r, fig.height=6, fig.width=9}
MA_model <- rma.mv(lnRR, VCV_lnRR, 
              random = list(~1|Study_ID,
                            ~1|Phylogeny, # Removed Cohort_ID
                            ~1|Species_common, 
                            ~1|PFAS_type, 
                            ~1|Effect_ID), 
              R= list(Phylogeny = cor_tree), 
              test = "t", 
              data = dat)

summary(MA_model)
i2_ml(MA_model) # Percentage of heterogeneity explained by each random effect

# plot
orchard_plot(MA_model, mod = "Int", xlab = "lnRR") # Orchard plot 

save(MA_model, MA_all_rand_effects, file = here("Rdata", "int_MA_models.RData")) # save the models 
```


```{r, include = FALSE}
# Because the models are saved, this code chunk can be used to see the models output without running the models
load(here("Rdata", "int_MA_models.RData"))

summary(MA_all_rand_effects)
summary(MA_model)

i2_ml(MA_model)

```


# **Meta-regressions**

## Function to run all models with the same structure

```{r}
run_model<-function(data,formula){
  data<-as.data.frame(data) # convert data set into a data frame to calculate VCV matrix 
  VCV<-make_VCV_matrix(data, V = "var_lnRR", cluster = "Cohort_ID", obs = "Effect_ID", rho = 0.5) # create VCV matrix for the specified data
  
  rma.mv(lnRR, VCV, # run the model, as described earlier
         mods=formula,
         random = list(~1|Study_ID,
                       ~1|Phylogeny, 
                       ~1|Species_common, 
                       ~1|PFAS_type, 
                       ~1|Effect_ID), 
         R= list(Phylogeny = cor_tree), 
         test = "t", 
         data = data)
}

```


## Function to run plots with the same structure

```{r}
plot_continuous<-function(data, model, moderator, xlab){
  
prediction <-predict.rma(model) 

figure <-  data %>% # getting ride of NA values
  mutate(ymin = prediction$ci.lb, 
         ymax = prediction$ci.ub,
         ymin2 = prediction$cr.lb,
         ymax2 = prediction$cr.ub,
         pred = prediction$pred) %>% 
  ggplot(aes(x = moderator, y = lnRR, size = (1/sqrt(var_lnRR)))) +
  geom_point(aes(fill = Cooking_Category), shape = 21) +
  geom_smooth(aes(y = ymin2), method =  "loess", se = FALSE, lty =  "dotdash", lwd = 0.5, colour = "purple") +
  geom_smooth(aes(y = ymax2), method =  "loess", se = FALSE, lty = "dotdash", lwd = 0.5, colour = "purple") +
  geom_smooth(aes(y = ymin), method =  "loess", se = FALSE,lty = "dotdash", lwd = 1, colour ="orange") +
  geom_smooth(aes(y = ymax), method =  "loess", se = FALSE, lty ="dotdash", lwd = 1, colour ="orange") + 
  geom_smooth(aes(y = pred), method =  "loess", se = FALSE, lty ="solid", lwd = 1.3, colour ="black") +  
  labs(x = xlab, y = "lnRR", size = "Precison (1/SE)") +
  theme_bw() +
  geom_hline(yintercept = 0,linetype = 2, colour = "black",alpha=0.5)+   # horizontal line at lnRR = 0
  theme(text = element_text(size = 18, colour = "black", hjust = 0.5), # change font sizes and legend position
          legend.position=c(0,0), 
          legend.justification = c(0,0),
          legend.background = element_blank(), 
          legend.direction="horizontal",
          legend.title = element_text(size=15))

figure
}

```


## Single-moderator models {.tabset .tabset_fade .tabset_pills} 

All continuous variables were z-transformed

### Cooking category 

```{r, fig.width=9, fig.height=6}
# Cooking_Category

category_model<-run_model(dat, ~Cooking_Category-1)
  
summary(category_model)
r2_ml(category_model)

# plot
orchard_plot(category_model, mod = "Cooking_Category", xlab = "lnRR")
```

### PFAS carbon chain length 

```{r, fig.width=10, fig.height=7}
# PFAS_carbon_chain

PFAS_model<-run_model(dat, ~PFAS_carbon_chain)
  
summary(PFAS_model)
r2_ml(PFAS_model)

plot_continuous(dat, PFAS_model, dat$PFAS_carbon_chain, "PFAS carbon chain length")
```

### Cooking temperature 

```{r, fig.width=10, fig.height=7}
# Temperature_in_Celsius

temp_model<-run_model(dat, ~scale(Temperature_in_Celsius)) # z-transformed 
  
summary(temp_model)
r2_ml(temp_model)

# Plot
dat.temp<-filter(dat, Temperature_in_Celsius!="NA")
plot_continuous(dat.temp, temp_model, dat.temp$Temperature_in_Celsius, "Cooking temperature")
```

### Cooking time 

```{r, fig.width=10, fig.height=7}
# Length_cooking_time_in_s

time_model<-run_model(dat, ~scale(Length_cooking_time_in_s)) # z-transformed
  
summary(time_model)
r2_ml(time_model)

# Plot
dat.time<-filter(dat, Length_cooking_time_in_s!="NA")
plot_continuous(dat.time, time_model, dat.time$Length_cooking_time_in_s, "Cooking time (s)")

```


### Volume of liquid 

```{r, fig.width=10, fig.height=7}
# Volume_liquid_ml

volume_model<-run_model(dat, ~scale(log(Volume_liquid_ml))) # logged and z-transformed
  
summary(volume_model)
r2_ml(volume_model)

# Plot
dat.volume<-filter(dat, Volume_liquid_ml!="NA")
plot_continuous(dat.volume, volume_model, log(dat.volume$Volume_liquid_ml), "Volume of liquid (mL)")
```


### Percentage of moisture loss

```{r, fig.width=10, fig.height=7}
# Moisture_loss_in_percent

moisture_model<-run_model(dat, ~scale(Moisture_loss_in_percent))
  
summary(moisture_model)
r2_ml(moisture_model)

# Plot
dat.moisture<-filter(dat, Moisture_loss_in_percent!="NA")
plot_continuous(dat.moisture, moisture_model, dat.moisture$Moisture_loss_in_percent, "Percentage of moisture loss")
```


```{r}
save(category_model, PFAS_model, temp_model, time_model, volume_model, moisture_model, file = here("Rdata", "single_mod_models.RData")) # Save models
```


```{r, include= FALSE}
load(here("Rdata", "single_mod_models.RData")) # Load the output of the models to avoid running them 

# Cooking category
summary(category_model)
r2_ml(category_model)

# PFAS carbon chain length
summary(PFAS_model)
r2_ml(PFAS_model)

# Cooking temperature
summary(temp_model)
r2_ml(temp_model)

# Cooking time
summary(time_model)
r2_ml(time_model)

# Volume of liquid
summary(volume_model)
r2_ml(volume_model)

# Percentage of moisture loss
summary(moisture_model)
r2_ml(moisture_model)
```


###


## Full model 

```{r}

# Full_model

full_model <- run_model(dat, ~ - 1 + 
                               Cooking_Category +
                               scale(Temperature_in_Celsius) +
                               scale(Length_cooking_time_in_s) +
                               scale(PFAS_carbon_chain) +
                               scale(log(Volume_liquid_ml)))
summary(full_model)
r2_ml(full_model)


save(full_model, file = here("Rdata", "full_model.RData"))
```

```{r, include = FALSE}

load(here("Rdata", "full_model.RData")) # Load the output of the full model to avoid running it

summary(full_model)
```



# **Conditional analyses** {.tabset .tabset_fade .tabset_pills} 

**SHOULD WE USE PROPORTIONAL OR EQUAL WEIGHTS????** 

Inspection of the plots highlighted potential significant decreases in PFAS content with increased cooking time and volume of cooking. 
Hence, here we used `emmeans` (download from *remotes::install_github("rvlenth/emmeans", dependencies = TRUE, build_opts = "")*) to generate marginalised means at specified values of the different predictors. 
Such analysis enable the quantification of the mean effect size after controlling for different values of the moderators. 

## Full model 

```{r}
# Full model in original units (not z-transformation)
dat$log_Volume_liquid_ml<-log(dat$Volume_liquid_ml)

full_model_org_units <- run_model(dat, ~ - 1 + 
                               Cooking_Category +
                               Temperature_in_Celsius +
                               Length_cooking_time_in_s +
                               PFAS_carbon_chain +
                               log_Volume_liquid_ml)


summary(full_model_org_units)

save(full_model, file = here("Rdata", "full_model_org_units.RData"))
```

```{r, include=FALSE}
load(here("Rdata", "full_model_org_units.RData")) # Load the output of the model to avoid running it

summary(full_model_org_units)
```


## Overall marginalised mean 

```{r}
res_mean_values <- qdrg(object = full_model_org_units, data = dat) # Generate an grid of marginal means at the mean of each predictor variable

emmeans(res_mean_values, specs = ~1, df = full_model_org_units$dfs) # Marginalised mean at the mean value of each predictor in the full model
# When all predictors at set to their mean level, the mean effect size is -1.59 (79.6 % decrease in PFAS content in experimental vs. control samples)
```

## Marginalised means for different cooking categories

```{r}
emmeans(res_mean_values, specs = "Cooking_Category", df = full_model_org_units$dfs)
```

## Marginalised means for pre-determined cooking times

Here, we generate estimates at cooking times of 2, 5, 10, 15, 20 and 25 min. 

```{r}
res_cooking_time <- qdrg(object = full_model_org_units, data = dat, at = list(Length_cooking_time_in_s = c(120, 300, 600, 900, 1200, 1500)))
```

### Marginalised mean estimate at each cooking time

```{r}
emmeans(res_cooking_time , specs = ~1 |  Length_cooking_time_in_s, df = full_model_org_units$dfs) 
```

### Marginalised mean estimate for each cooking category, at each cooking time

```{r}
emmeans(res_cooking_time , specs = ~ Cooking_Category |  Length_cooking_time_in_s, df = full_model_org_units$dfs) 
```

## Marginalised means for different volumes of liquid

Here, we generate marginalised estimates at volumes of liquid of ~10, 500, 1000, 5000 and 10000 mL. We did not look at the means for different cooking categories because they are inherently different in the volume of liquid used. 

```{r}
res_volume <- qdrg(object = full_model_org_units, data = dat, at = list(log_Volume_liquid_ml= c(2.3, 6.2, 6.9, 8.5, 9.2)))

emmeans(res_volume , specs = ~ 1 |  log_Volume_liquid_ml, df = full_model_org_units$dfs) 
```

## Marginalised means for different PFAS carbon chains

Here, we generate marginalised estimates for PFAS of 3, 6, 9 and 12 carbon chains

```{r}
res_PFAS <- qdrg(object = full_model_org_units, data = dat, at = list(PFAS_carbon_chain= c(3, 6, 9, 12)))
```


### Marginalised mean estimate for each PFAS carbon chain

```{r}
emmeans(res_PFAS, specs = ~ 1 |  PFAS_carbon_chain, df = full_model_org_units$dfs) 
```

### Marginalised mean estimate for each PFAS carbon chain, for each cooking category 

```{r}
emmeans(res_PFAS, specs = ~ Cooking_Category |  PFAS_carbon_chain, df = full_model_org_units$dfs) 
```
##


# **Subset analyses** for each cooking category {.tabset .tabset_fade .tabset_pills} 

Here, we investigated whether the effect of the continuous moderators on lnRR vary depending on the cooking category. Hence, we performed subset analyses for each cooking category. 

## Oil-based cooking

### Subset data and update function
```{r}
oil_dat<-filter(dat, Cooking_Category=="oil-based")

include <- row.names(cor_tree) %in% oil_dat$Phylogeny # Check which rows are present in the phylogenetic tree 
cor_tree_oil <- cor_tree[include, include] # Only include the species that match the reduced data set 


run_model_oil<-function(data,formula){
  data<-as.data.frame(data) # convert data set into a data frame to calculate VCV matrix 
  VCV<-make_VCV_matrix(data, V = "var_lnRR", cluster = "Cohort_ID", obs = "Effect_ID", rho = 0.5) # create VCV matrix for the specified data
  
  rma.mv(lnRR, VCV, # run the model, as described earlier
         mods=formula,
         random = list(~1|Study_ID,
                       ~1|Phylogeny, 
                       ~1|Species_common, 
                       ~1|PFAS_type, 
                       ~1|Effect_ID), 
         R= list(Phylogeny = cor_tree_oil), # cor_tree_oil here
         test = "t", 
         data = data)
}
```

### Full model 

```{r}
full_model_oil <- run_model_oil(oil_dat, ~ scale(Temperature_in_Celsius) +
                                           scale(Length_cooking_time_in_s) +
                                           scale(PFAS_carbon_chain) +
                                           scale(log(Volume_liquid_ml)))
                 
summary(full_model_oil)

save(full_model_oil, file = here("Rdata", "full_model_oil.RData"))
```

```{r, include=F}
load(here("Rdata", "full_model_oil.RData"))
summary(full_model_oil)
```


## Water-based cooking

### Subset data and updating functions
```{r}
water_dat<-filter(dat, Cooking_Category=="water-based")

include <- row.names(cor_tree) %in% water_dat$Phylogeny # Check which rows are present in the phylogenetic tree 
cor_tree_water <- cor_tree[include, include] # Only include the species that match the reduced data set 


run_model_water<-function(data,formula){
  data<-as.data.frame(data) # convert data set into a data frame to calculate VCV matrix 
  VCV<-make_VCV_matrix(data, V = "var_lnRR", cluster = "Cohort_ID", obs = "Effect_ID", rho = 0.5) # create VCV matrix for the specified data
  
  rma.mv(lnRR, VCV, # run the model, as described earlier
         mods=formula,
         random = list(~1|Study_ID,
                       ~1|Phylogeny, 
                       ~1|Species_common, 
                       ~1|PFAS_type, 
                       ~1|Effect_ID), 
         R= list(Phylogeny = cor_tree_water), # cor_tree_water here
         test = "t", 
         data = data)
}
```


### Full model 

```{r}
full_model_water <- run_model_water(water_dat, ~ scale(Temperature_in_Celsius) +
                                           scale(Length_cooking_time_in_s) +
                                           scale(PFAS_carbon_chain) +
                                           scale(log(Volume_liquid_ml)))
                 
summary(full_model_water)

save(full_model_water, file = here("Rdata", "full_model_water.RData"))
```


```{r, include=F}
load(here("Rdata", "full_model_water.RData"))
summary(full_model_water)
```


## Dry cooking 

Not very relevant because all effect sizes are from one study here. Also, the model does not converge when adding `VCV_lnRR`
```{r}
dry_dat<-filter(dat, Cooking_Category=="No liquid")

include <- row.names(cor_tree) %in% dry_dat$Phylogeny # Check which rows are present in the phylogenetic tree 
cor_tree_dry <- cor_tree[include, include] # Only include the species that match the reduced data set 


run_model_dry<-function(data,formula){
  data<-as.data.frame(data) # convert data set into a data frame to calculate VCV matrix 
  rma.mv(lnRR, var_lnRR, # run the model with var_lnRR instead of lnCVR
         mods=formula,
         random = list(~1|Study_ID,
                       ~1|Phylogeny, 
                       ~1|Species_common, 
                       ~1|PFAS_type, 
                       ~1|Effect_ID), 
         R= list(Phylogeny = cor_tree_dry), # cor_tree_dry here
         test = "t", 
         data = data)
}
```


### Full model 


```{r}
full_model_dry <- run_model_dry(dry_dat, ~ scale(Length_cooking_time_in_s)) # Nodel does not converge with VCV_lnRR
                 
summary(full_model_dry)

save(full_model_dry, file = here("Rdata", "full_model_dry.RData"))
```


```{r, include=F}
load(here("Rdata", "full_model_dry.RData"))
summary(full_model_dry)
```

##


# **Plots** {.tabset .tabset_fade .tabset_pills} 

**NEED TO DISCUSS WHAT IS THE MOST RELEVANT**
We can either separate oil and water-based in different plots, or, on the same plot, add multiple regression lines. 
I did it for cooking time, similar code can be applied to the other predictors. 

Need to do plots for Volume and PFAS carbon chain as well. 

## Cooking time

### Generate predictions
```{r}

### Oil-based 
oil_dat_time<-filter(oil_dat, Length_cooking_time_in_s!="NA") # Create a subset of oil data without missing cooking time


oil_time_model<-run_model_oil(oil_dat_time, ~Length_cooking_time_in_s) # Run model with just cooking time
pred_oil_time_model<- predict.rma(oil_time_model) # predict values


oil_dat_time <- mutate(oil_dat_time,
                    ymin = pred_oil_time_model$ci.lb, # lower bound of the confidence interval for oil
                    ymax = pred_oil_time_model$ci.ub, # upper bound of the confidence interval for oil
                    ypred = pred_oil_time_model$pred) # regression line for oil

### Water-based

water_dat_time<-filter(water_dat, Length_cooking_time_in_s!="NA") # Create a subset of water data without missing cooking time


water_time_model<-run_model_water(water_dat_time, ~Length_cooking_time_in_s) # Run model with just cooking time
pred_water_time_model<- predict.rma(water_time_model) # predict values


water_dat_time <- mutate(water_dat_time,
                    zmin = pred_water_time_model$ci.lb, # lower bound of the confidence interval for water
                    zmax = pred_water_time_model$ci.ub, # upper bound of the confidence interval for water
                    zpred = pred_water_time_model$pred) # regression line for water

### Dry 


dry_dat_time<-filter(dry_dat, Length_cooking_time_in_s!="NA") # Create a subset of dry data without missing cooking time


dry_time_model<-run_model_dry(dry_dat_time, ~ Length_cooking_time_in_s) # Run model with just cooking time
pred_dry_time_model<- predict.rma(dry_time_model) # predict values


dry_dat_time <- mutate(dry_dat_time,
                    wmin = pred_dry_time_model$ci.lb, # lower bound of the confidence interval for dry
                    wmax = pred_dry_time_model$ci.ub, # upper bound of the confidence interval for dry
                    wpred = pred_dry_time_model$pred) # regression line for dry
```
### Plot
```{r, fig.height=8, fig.width=10}

ggplot(dat,aes(x = Length_cooking_time_in_s, y = lnRR, size = (1/sqrt(var_lnRR)),col= Cooking_Category)) + 
   
       geom_point(alpha=0.5) + scale_color_manual(values=c("gray30","goldenrod2", "mediumblue"))+
  
       geom_smooth(data=oil_dat_time,aes(y = ymin), method = "loess", se = FALSE, lty = "dotdash", lwd = 0.75, colour = "goldenrod2") + # add lower confidence interval of oil
       geom_smooth(data=oil_dat_time,aes(y = ymax), method = "loess", se = FALSE, lty = "dotted", lwd = 0.75, colour = "goldenrod2") + # add upper confidence interval of oil
       geom_smooth(data=oil_dat_time, aes(y = ypred), method = "loess", se = FALSE, lty = "solid", lwd = 1.8, colour = "goldenrod2") + # add regression line of oil
  
       geom_smooth(data=water_dat_time,aes(y = zmin), method = "loess", se = FALSE, lty = "dotdash", lwd = 0.75, colour = "mediumblue") + # add lower CI of water
       geom_smooth(data=water_dat_time,aes(y = zmax), method = "loess", se = FALSE, lty = "dotdash", lwd = 0.75, colour = "mediumblue") + # add upper CI of water
       geom_smooth(data=water_dat_time,aes(y = zpred), method = "loess", se = FALSE, lty = "solid", lwd = 1.8, colour = "mediumblue") + # add regression line of water
  
       geom_smooth(data=dry_dat_time,aes(y = wmin), method = "loess", se = FALSE, lty = "dotdash", lwd = 0.75, colour = "gray30") + # add lower CI of dry
       geom_smooth(data=dry_dat_time,aes(y = wmax), method = "loess", se = FALSE, lty = "dotdash", lwd = 0.75, colour = "gray30") + # add upper CI of dry
       geom_smooth(data=dry_dat_time,aes(y = wpred), method = "loess", se = FALSE, lty = "solid", lwd = 1.8, colour = "gray30") +# add regression line of dry
  
  
         labs(x = "Cooking time (s)", y = "lnRR", size = "Precision (1/SE)") + 
         geom_hline(yintercept = 0,linetype = 2, colour = "black",alpha=0.5)+
         scale_size_continuous(range = c(1, 9))+
         theme_bw() + 
         theme(legend.position = c(1, 1), 
               legend.justification = c(1, 1),
               legend.direction = "horizontal",
               legend.background = element_blank(),
               text = element_text(size = 20, colour = "black", hjust = 0.5),
               legend.title = element_text(size=16))

```


## 



# **Publication bias** {.tabset .tabset_fade .tabset_pills} 

## Funnel plot 

```{r}
funnel(full_model, yaxis = "seinv")
```

## Egger regressions 

```{r}
egger_all <- run_model(dat, ~ - 1 + Cooking_Category +
                      I(sqrt(1/N_tilde)) + 
                      scale(Publication_year) + 
                      scale(Temperature_in_Celsius) +
                      scale(Length_cooking_time_in_s) +
                      scale(PFAS_carbon_chain) +
                      scale(log(Volume_liquid_ml)))
summary(egger_all)

#funnel(egger_all, yaxis = "seinv")
# little evidence
egger_n <- run_model(dat, ~ I(sqrt(1/N_tilde)))
summary(egger_n)

save(egger_all, egger_n, file = here("Rdata", "egger_regressions.RData"))
```

